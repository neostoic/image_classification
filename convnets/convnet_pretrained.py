# Train two simple deep CNN on the Yelp data using batch processing in Griffin cluster.
# Based on the Keras examples by Francois Chollet, available at:
# https://github.com/fchollet/keras/blob/master/examples/cifar10_cnn.py

# GPU Usage: `THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python convnet_pretrained.py`

from __future__ import print_function

from multiprocessing import freeze_support

import numpy as np
from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D
from keras.layers.core import Dense, Dropout, Activation, Flatten
from keras.models import Sequential
from keras.optimizers import SGD
from keras.preprocessing.image import ImageDataGenerator

from batches.batchgen import BatchGen
from batches.load_batch import batch

MODELS = ['VGG_16', 'VGG_19', 'googlenet', 'inception_v3']


def train(model_='VGG_16'):
    batch_size = 8
    nb_samples = 2000
    nb_classes = 5
    nb_epoch = 10
    data_augmentation = False
    train_pkl = r'./data/restaurant_photos_with_labels_train.pkl'
    test_pkl = r'./data/restaurant_photos_with_labels_test.pkl'
    img_path = r'./data/restaurant_photos/'

    # input image dimensions
    if model_ in MODELS[0:2]:
        img_rows, img_cols = 224, 224
    if model_ in MODELS[3]:
        img_rows, img_cols = 299, 299
    # the CIFAR10 images are RGB
    img_channels = 3

    # generate model
    if model_ in MODELS[0]:
        network = VGG_16(img_rows, img_cols, img_channels, nb_classes)

    # let's train the model using SGD + momentum (how original).
    sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
    network.compile(loss='categorical_crossentropy', optimizer=sgd)

    with BatchGen(batch, seed=1, num_workers=1, input_pkl=train_pkl, test_pkl=test_pkl, img_path=img_path,
                  dtype=np.float32, pixels=img_rows, model=model_, batch_size=batch_size) as bg:
        for i in range(nb_samples):
            minibatch = next(bg)
            X_train = minibatch['x_train']
            y_train = minibatch['y_train']
            X_test = minibatch['x_test']
            y_test = minibatch['y_test']

            print('X_train shape:', X_train.shape)
            print(X_train.shape[0], 'train samples')
            print(X_test.shape[0], 'test samples')

            if not data_augmentation:
                print('Not using data augmentation.')
                network.fit(X_train, y_train, batch_size=batch_size,
                            nb_epoch=nb_epoch, show_accuracy=True,
                            validation_data=(X_test, y_test), shuffle=True)
            else:
                print('Using real-time data augmentation.')

                # this will do preprocessing and realtime data augmentation
                datagen = ImageDataGenerator(
                    featurewise_center=False,  # set input mean to 0 over the dataset
                    samplewise_center=False,  # set each sample mean to 0
                    featurewise_std_normalization=False,  # divide inputs by std of the dataset
                    samplewise_std_normalization=False,  # divide each input by its std
                    zca_whitening=False,  # apply ZCA whitening
                    rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)
                    width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)
                    height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)
                    horizontal_flip=True,  # randomly flip images
                    vertical_flip=False)  # randomly flip images

                # compute quantities required for featurewise normalization
                # (std, mean, and principal components if ZCA whitening is applied)
                datagen.fit(X_train)

                # fit the model on the batches generated by datagen.flow()
                network.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),
                                      samples_per_epoch=X_train.shape[0],
                                      nb_epoch=nb_epoch, show_accuracy=True,
                                      validation_data=(X_test, y_test),
                                      nb_worker=1)


# Define the VGG-16 model structure
def VGG_16(img_rows, img_cols, img_channels=3, nb_classes=5, weights_path=None):
    model = Sequential()
    model.add(ZeroPadding2D((1, 1), input_shape=(img_channels, img_rows, img_cols)))
    model.add(Convolution2D(64, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(64, 3, 3, activation='relu'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(128, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(128, 3, 3, activation='relu'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(256, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(256, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(256, 3, 3, activation='relu'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(ZeroPadding2D((1, 1)))
    model.add(Convolution2D(512, 3, 3, activation='relu'))
    model.add(MaxPooling2D((2, 2), strides=(2, 2)))

    model.add(Flatten())
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nb_classes, activation='softmax'))

    if weights_path:
        model.load_weights(weights_path)

    return model


# Define the simple CIFAR10-based model
def CIFAR_10(img_rows, img_cols, img_channels=3, nb_classes=5, weights_path=None):
    model = Sequential()

    model.add(Convolution2D(32, 3, 3, border_mode='same',
                            input_shape=(img_channels, img_rows, img_cols)))
    model.add(Activation('relu'))
    model.add(Convolution2D(32, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Convolution2D(64, 3, 3, border_mode='same'))
    model.add(Activation('relu'))
    model.add(Convolution2D(64, 3, 3))
    model.add(Activation('relu'))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Dropout(0.25))

    model.add(Flatten())
    model.add(Dense(512))
    model.add(Activation('relu'))
    model.add(Dropout(0.5))
    model.add(Dense(nb_classes))
    model.add(Activation('softmax'))

    if weights_path:
        model.load_weights(weights_path)

    return model


if __name__ == '__main__':
    freeze_support()
    train('VGG_16')
